{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpqbFInxrYdL"
      },
      "source": [
        "# Colab-VSGAN\n",
        "\n",
        "My repo: [styler00dollar/VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker/)\n",
        "\n",
        "Since it was tried to keep things modular and save on install time, you need to pick on what to install yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfWp19tKePiR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50YNOoUCgcbM"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfnge1eeR4C"
      },
      "outputs": [],
      "source": [
        "# check python version, for me its currently 3.8.10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4LVR-piSdQRT"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8QneOIbHW9TK"
      },
      "outputs": [],
      "source": [
        "#@title Install TensorRT 8.5.x\n",
        "%cd /content\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libnvinfer8 libnvonnxparsers8 libnvparsers8 libnvinfer-plugin8 libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev python3-libnvinfer tensorrt python3-libnvinfer-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sOBWyltT6JUY"
      },
      "outputs": [],
      "source": [
        "#@title initial setup\n",
        "%cd /content/\n",
        "!sudo rm -rf /workspace\n",
        "!mkdir -p /workspace/tensorrt\n",
        "%cd /workspace/tensorrt\n",
        "!git clone https://github.com/styler00dollar/VSGAN-tensorrt-docker\n",
        "\n",
        "!pip install kornia opencv-python pytorch-msssim thop einops timm wget\n",
        "\n",
        "!wget https://github.com/styler00dollar/VSGAN-tensorrt-docker/releases/download/models/ffmpeg && \\\n",
        "    chmod +x ffmpeg && sudo rm -rf /usr/bin/ffmpeg && mv ffmpeg /usr/bin/ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download all dependencies\n",
        "%cd /content\n",
        "!pip uninstall cupy-cuda11x -y\n",
        "\n",
        "!mkdir vs_precompiled_colab\n",
        "%cd vs_precompiled_colab\n",
        "!wget https://github.com/styler00dollar/VSGAN-tensorrt-docker/releases/download/models/vs_precompiled_colab.7z\n",
        "!7z x vs_precompiled_colab.7z\n",
        "\n",
        "!mkdir -p /usr/local/lib/vapoursynth/\n",
        "!mkdir -p /usr/local/lib/x86_64-linux-gnu/\n",
        "\n",
        "!cp /content/vs_precompiled_colab/usr_local_bin/vspipe /usr/local/bin/vspipe\n",
        "!mv /content/vs_precompiled_colab/usr_local_lib/* /usr/local/lib\n",
        "!sudo ldconfig\n",
        "!chmod +x /usr/local/bin/vspipe\n",
        "\n",
        "!pip install /content/vs_precompiled_colab/whl/* scenedetect onnxruntime-gpu vsbasicvsrpp vsswinir https://github.com/pytorch/TensorRT/releases/download/v1.3.0/torch_tensorrt-1.3.0-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "# upgrading g++ and installing ffms2\n",
        "!sudo apt install build-essential manpages-dev software-properties-common ffmsindex libffms2-4 libffms2-dev -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
        "!sudo apt update -y && sudo apt install gcc-11 g++-11 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11\n",
        "\n",
        "%cd /content\n",
        "!rm -rf deb_files\n",
        "!mkdir deb_files\n",
        "%cd deb_files\n",
        "!wget http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/locales_2.36-0ubuntu4_all.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/libc6_2.36-0ubuntu4_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/libc6-dev_2.36-0ubuntu4_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/libc-bin_2.36-0ubuntu4_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/libc-dev-bin_2.36-0ubuntu4_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/libn/libnsl/libnsl2_1.3.0-2build2_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/libn/libnsl/libnsl-dev_1.3.0-2build2_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/libt/libtirpc/libtirpc3_1.3.3+ds-1_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/libt/libtirpc/libtirpc-common_1.3.3+ds-1_all.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/libt/libtirpc/libtirpc-dev_1.3.3+ds-1_amd64.deb \\\n",
        "    http://mirrors.kernel.org/ubuntu/pool/main/r/rpcsvc-proto/rpcsvc-proto_1.4.2-0ubuntu6_amd64.deb && \\\n",
        "    dpkg --force all -i *.deb"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k36bnZVq6eWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2ICcFHVcdtLP"
      },
      "outputs": [],
      "source": [
        "#@title ffmpeg (nix)\n",
        "#@markdown Get ffmpeg from nix. Use this to get the nix version of ffmpeg-full instead of my self compiled ffmpeg or if you want to use nvenc. The only difference is, that to use this ffmpeg, you need to use `deroot ffmpeg -i ...`.\n",
        "%cd /content\n",
        "!git clone https://github.com/styler00dollar/nix-on-colab  /tmp/nix-on-colab\n",
        "!/tmp/nix-on-colab/setup\n",
        "!deroot nix run nixpkgs\n",
        "!deroot nix-env -iA nixpkgs.ffmpeg_5-full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a3Fp70p-LND"
      },
      "source": [
        "# (optional) Other cells for modular install / compiling manually\n",
        "run them in correct order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0ShahTu5Xhl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title compile vs\n",
        "# installing vapoursynth related stuff\n",
        "!apt install autoconf libtool yasm python3.9 python3.9-venv python3.9-dev ffmsindex libffms2-4 libffms2-dev -y\n",
        "!apt --fix-broken install\n",
        "# zimg\n",
        "!wget https://github.com/sekrit-twc/zimg/archive/refs/tags/release-3.0.4.zip && 7z x release-3.0.4.zip\n",
        "%cd zimg-release-3.0.4\n",
        "!./autogen.sh && ./configure && make -j4 && make install\n",
        "# vapoursynth\n",
        "!pip install Cython -U --force-reinstall\n",
        "!git clone https://github.com/vapoursynth/vapoursynth\n",
        "%cd vapoursynth\n",
        "!./autogen.sh && ./configure && make && make install && cd .. && ldconfig\n",
        "!ln -s /usr/local/lib/python3.8/site-packages/vapoursynth.so /usr/lib/python3.8/lib-dynload/vapoursynth.so\n",
        "!pip install vapoursynth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMKQ9b2N7ebW"
      },
      "source": [
        "Optional stuff, which you may or may not need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4jV5zwP15-1A"
      },
      "outputs": [],
      "source": [
        "#@title install cupy / pycuda\n",
        "!curl https://colab.chainer.org/install | sh -\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VFuIsOxq6BcN"
      },
      "outputs": [],
      "source": [
        "#@title install Torch-TensorRT\n",
        "# pytorch tensorrt\n",
        "!pip install https://github.com/pytorch/TensorRT/releases/download/v1.2.0/torch_tensorrt-1.2.0-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CHstsMhB6DrM"
      },
      "outputs": [],
      "source": [
        "#@title install onnx\n",
        "!pip install onnx onnxruntime onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2j4UsWPo6FP9"
      },
      "outputs": [],
      "source": [
        "#@title install Onnx-TensorRT\n",
        "!pip install nvidia-pyindex nvidia-tensorrt pycuda\n",
        "%cd /workspace/tensorrt\n",
        "!git clone https://github.com/onnx/onnx-tensorrt\n",
        "%cd onnx-tensorrt\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FADjGboe6L3I"
      },
      "outputs": [],
      "source": [
        "#@title install swinir\n",
        "# vs plugings from others\n",
        "# https://github.com/HolyWu/vs-swinir\n",
        "!pip install --upgrade vsswinir && python -m vsswinir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5FsVoy_R_2B-"
      },
      "outputs": [],
      "source": [
        "#@title compile mmcv + install vsbasicvsrpp (basicvsrpp/RealBasicVSR)\n",
        "# https://github.com/HolyWu/vs-basicvsrpp\n",
        "!pip install --upgrade vsbasicvsrpp && python -m vsbasicvsrpp\n",
        "# dependencies for RealBasicVSR_x4\n",
        "# mmedit\n",
        "!git clone https://github.com/open-mmlab/mmediting.git && cd mmediting && pip install -v -e .\n",
        "# RealBasicVSR_x4 will download this\n",
        "!wget \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" -P /root/.cache/torch/hub/checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hnUyOWKZc91g"
      },
      "outputs": [],
      "source": [
        "#@title download pytorch models \n",
        "%cd /workspace/tensorrt/\n",
        "!sh download_models.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hWt-eyFSWRlw"
      },
      "outputs": [],
      "source": [
        "#@title install g++11\n",
        "!sudo apt install build-essential manpages-dev software-properties-common -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
        "!sudo apt update -y && sudo apt install gcc-11 g++-11 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIjnFDGP7maV"
      },
      "outputs": [],
      "source": [
        "#@title compile vs-mlrt (needs g++11)\n",
        "# updating cmake\n",
        "%cd /content\n",
        "!wget https://github.com/Kitware/CMake/releases/download/v3.24.0-rc1/cmake-3.24.0-rc1-linux-x86_64.sh\n",
        "!chmod +x cmake-3.24.0-rc1-linux-x86_64.sh\n",
        "!sh cmake-3.24.0-rc1-linux-x86_64.sh --skip-license\n",
        "!cp /content/bin/cmake /usr/bin/cmake\n",
        "!cp /content/bin/cmake /usr/lib/x86_64-linux-gnu/cmake\n",
        "!cp /content/bin/cmake /usr/local/bin/cmake\n",
        "!cp -r /content/share/cmake-3.24 /usr/local/share/\n",
        "# getting vapoursynth sourcecode\n",
        "%cd /content\n",
        "!wget https://github.com/vapoursynth/vapoursynth/archive/refs/tags/R60.zip\n",
        "!7z x R60.zip\n",
        "# compiling\n",
        "%cd /content/\n",
        "!sudo rm -rf vs-mlrt\n",
        "!git clone https://github.com/AmusementClub/vs-mlrt\n",
        "%cd vs-mlrt/vstrt\n",
        "!mkdir build\n",
        "%cd build\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 cmake .. -DVAPOURSYNTH_INCLUDE_DIRECTORY=/content/vapoursynth-R60/include\n",
        "!make\n",
        "!sudo make install\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H42DQGlPUTVD"
      },
      "outputs": [],
      "source": [
        "#@title compile VMAF (needs compiled vs and g++11)\n",
        "%cd /content\n",
        "!apt install nasm -y\n",
        "!pip install ninja meson\n",
        "\n",
        "!rm -rf vmaf-2.3.1\n",
        "!wget https://github.com/Netflix/vmaf/archive/refs/tags/v2.3.1.tar.gz\n",
        "# VMAF\n",
        "!tar -xzf  v2.3.1.tar.gz\n",
        "%cd vmaf-2.3.1/libvmaf/\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 meson build --buildtype release\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 ninja -C build && ninja -C build install\n",
        "\n",
        "%cd /content\n",
        "!rm -rf VapourSynth-VMAF\n",
        "!git clone https://github.com/HomeOfVapourSynthEvolution/VapourSynth-VMAF\n",
        "%cd VapourSynth-VMAF\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 meson build\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 ninja -C build && ninja -C build install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IB4QByhoNe4B"
      },
      "outputs": [],
      "source": [
        "#@title compile stuff for ddfi (VFRToCFR, mvtools, fmtconv) (needs compiled vs)\n",
        "%cd /content\n",
        "!apt install nasm fftw3-dev -y\n",
        "!pip install ninja meson\n",
        "\n",
        "# Vapoursynth-VFRToCFR\n",
        "!sudo rm -rf Vapoursynth-VFRToCFR\n",
        "!git clone https://github.com/Irrational-Encoding-Wizardry/Vapoursynth-VFRToCFR && cd Vapoursynth-VFRToCFR && \\\n",
        "    mkdir build && cd build && meson --buildtype release .. && ninja && ninja install\n",
        "\n",
        "# vapoursynth-mvtools\n",
        "%cd /content\n",
        "!sudo rm -rf vapoursynth-mvtools\n",
        "!git clone https://github.com/dubhater/vapoursynth-mvtools && cd vapoursynth-mvtools && ./autogen.sh && ./configure && make && make install\n",
        "\n",
        "# fmtconv\n",
        "%cd /content\n",
        "!sudo rm -rf fmtconv\n",
        "!git clone https://github.com/EleonoreMizo/fmtconv && cd fmtconv/build/unix/ && ./autogen.sh && ./configure && make && make install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuSs44vL8BW1"
      },
      "source": [
        "Vulkan related:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bEj3zNnb6Q28"
      },
      "outputs": [],
      "source": [
        "#@title install vulkan\n",
        "!sudo apt-get install -y libvulkan-dev nasm\n",
        "!pip install meson ninja\n",
        "# upgrading g++\n",
        "!sudo apt install build-essential manpages-dev software-properties-common -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
        "!sudo apt update -y && sudo apt install gcc-11 g++-11 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NiXni12z6SBK"
      },
      "outputs": [],
      "source": [
        "#@title compile rife ncnn (needs compiled vs, VMAF and g++11)\n",
        "# MISC\n",
        "%cd /content\n",
        "!rm -rf vs-miscfilters-obsolete\n",
        "!git clone https://github.com/vapoursynth/vs-miscfilters-obsolete\n",
        "%cd vs-miscfilters-obsolete\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 meson build\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 ninja -C build && ninja -C build install\n",
        "    \n",
        "# RIFE\n",
        "%cd /content\n",
        "!rm -rf VapourSynth-RIFE-ncnn-Vulkan\n",
        "!git clone https://github.com/styler00dollar/VapourSynth-RIFE-ncnn-Vulkan\n",
        "%cd VapourSynth-RIFE-ncnn-Vulkan\n",
        "!git submodule update --init --recursive --depth 1\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 meson build\n",
        "!CC=/usr/bin/gcc-11 CXX=/usr/bin/g++-11 ninja -C build && ninja -C build install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYOLNSQP8EUb"
      },
      "source": [
        "Rendering related:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yK6leYum6NzX"
      },
      "outputs": [],
      "source": [
        "#@title install x264\n",
        "# render tools\n",
        "!sudo apt install x264 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2PCAkLF57rM2"
      },
      "outputs": [],
      "source": [
        "#@title compile x265\n",
        "!sudo apt-get install -y numactl\n",
        "# updating cmake\n",
        "%cd /content\n",
        "!wget https://github.com/Kitware/CMake/releases/download/v3.23.0-rc1/cmake-3.23.0-rc1-linux-x86_64.sh\n",
        "!chmod +x cmake-3.23.0-rc1-linux-x86_64.sh\n",
        "!sh cmake-3.23.0-rc1-linux-x86_64.sh --skip-license\n",
        "!cp /content/bin/cmake /usr/bin/cmake\n",
        "!cp /content/bin/cmake /usr/lib/x86_64-linux-gnu/cmake\n",
        "!cp /content/bin/cmake /usr/local/bin/cmake\n",
        "!cp -r /content/share/cmake-3.23 /usr/local/share/\n",
        "# upgrading g++\n",
        "!sudo apt install build-essential manpages-dev software-properties-common -y\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
        "!sudo apt update -y && sudo apt install gcc-11 g++-11 -y\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 11\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 11\n",
        "# compile x265\n",
        "%cd /content\n",
        "!sudo rm -rf x265\n",
        "!git clone https://github.com/AmusementClub/x265\n",
        "%cd x265/source/\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake .. -DNATIVE_BUILD=ON -DSTATIC_LINK_CRT=ON -DENABLE_AVISYNTH=OFF\n",
        "!make \n",
        "!sudo make install\n",
        "!cp /content/x265/source/build/x265 /usr/bin/x265 \n",
        "!cp /content/x265/source/build/x265 /usr/local/bin/x265"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTuK32lZyMFC"
      },
      "source": [
        "`Runtime -> Restart runtime`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED6eNarwobuR"
      },
      "source": [
        "# Render"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSQxoSnXOJq0"
      },
      "outputs": [],
      "source": [
        "# if you want to use vs-mlrt, convert model into engine, you can find models in /content/models\n",
        "# after creating the model, you can set the path in inference.py\n",
        "%cd /content\n",
        "!/usr/src/tensorrt/bin/trtexec --fp16 --onnx=/content/model.onnx --minShapes=input:1x3x8x8 --optShapes=input:1x3x720x1280 --maxShapes=input:1x3x1080x1920 --saveEngine=/content/model.engine --tacticSources=+CUDNN,+CUBLAS,+CUBLAS_LT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy7HkJ6XOO3s"
      },
      "source": [
        "# Normal inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xuve_1Xmzmu"
      },
      "source": [
        "sys.path.append('/workspace/tensorrt/VSGAN-tensorrt-docker/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1YCas1zB-Dv"
      },
      "source": [
        "The default installation by downloading dependencies does not include vsbasicvsrpp and "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eE1mgrLom8qI"
      },
      "outputs": [],
      "source": [
        "#@title inference.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/inference.py\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "from inference_config import inference_clip\n",
        "\n",
        "video_path = \"/workspace/tensorrt/VSGAN-tensorrt-docker/720.mkv\"\n",
        "clip = inference_clip(video_path)\n",
        "clip.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rfFwJycObJ2I"
      },
      "outputs": [],
      "source": [
        "#@title inference_config.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/inference_config.py\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "import vapoursynth as vs\n",
        "\n",
        "# video imports\n",
        "from src.vfi_inference import vfi_inference\n",
        "from src.vfi_model import video_model\n",
        "\n",
        "from src.rife import RIFE\n",
        "from src.IFRNet import IFRNet\n",
        "from src.GMFupSS import GMFupSS\n",
        "from src.GMFSS_union import GMFSS_union\n",
        "from src.eisai import EISAI\n",
        "from src.film import FILM\n",
        "from src.M2M import M2M\n",
        "from src.sepconv_enhanced import sepconv\n",
        "from src.IFUNet import IFUNet\n",
        "from src.stmfnet import STMFNet\n",
        "from src.rife_trt import rife_trt\n",
        "\n",
        "# upscale imports\n",
        "from src.upscale_inference import upscale_inference\n",
        "from src.pan import PAN_inference\n",
        "from src.realbasicvsr import realbasicvsr_inference\n",
        "from src.egvsr import egvsr_inference\n",
        "from src.cugan import cugan_inference\n",
        "from vsbasicvsrpp import BasicVSRPP\n",
        "from vsswinir import SwinIR\n",
        "from src.SRVGGNetCompact import compact_inference\n",
        "\n",
        "# from src.esrgan import ESRGAN_inference\n",
        "\n",
        "# image processing imports\n",
        "from src.scunet import scunet_inference\n",
        "\n",
        "from src.scene_detect import scene_detect\n",
        "\n",
        "core = vs.core\n",
        "vs_api_below4 = vs.__api_version__.api_major < 4\n",
        "core = vs.core\n",
        "core.num_threads = 4  # can influence ram usage\n",
        "# only needed if you are inside docker\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libvstrt.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libscxvid.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libwwxd.so\")\n",
        "\n",
        "\n",
        "def inference_clip(video_path=\"\", clip=None):\n",
        "    # ddfi is passing clip\n",
        "    if clip is None:\n",
        "        # cfr video\n",
        "        clip = core.ffms2.Source(source=video_path, cache=False)\n",
        "        # vfr video\n",
        "        # clip = core.ffms2.Source(source=video_path, fpsnum = 24000, fpsden = 1001, cache=False)\n",
        "        # vfr video (automatically set num and den)\n",
        "        # clip = core.ffms2.Source(source=video_path, fpsnum = -1, fpsden = 1, cache=False)\n",
        "\n",
        "        # lsmash\n",
        "        # clip = core.lsmas.LWLibavSource(source=video_path)\n",
        "        \n",
        "        # resizing with descale\n",
        "        # Debilinear, Debicubic, Delanczos, Despline16, Despline36, Despline64, Descale\n",
        "        #clip = core.descale.Debilinear(clip, 1280, 720)\n",
        "\n",
        "    ###############################################\n",
        "    # SIMILARITY\n",
        "    # Set properties in clip for it to be applied\n",
        "    # SSIM for deduplication in frame interpolation\n",
        "\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # 0 = PSNR, 1 = PSNR-HVS, 2 = SSIM, 3 = MS-SSIM, 4 = CIEDE2000\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "\n",
        "    # SCENE DETECT\n",
        "    # clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "    # clip = core.scxvid.Scxvid(clip, use_slices=True) # todo\n",
        "    # clip = core.wwxd.WWXD(clip=clip) # todo\n",
        "\n",
        "    # model based scene detect needs RGBS as input\n",
        "    # clip = scene_detect(clip, model_name=\"efficientnetv2_b0\", thresh=0.98, fp16=False)\n",
        "\n",
        "    # dedup (requires you to call \"vspipe parse.py -p .\" to generate infos_running.txt and tmp.txt)\n",
        "    #from src.dedup import get_dedup_frames\n",
        "    #frames_duplicated, frames_duplicating = get_dedup_frames()\n",
        "    #clip = core.std.DeleteFrames(clip, frames_duplicated)\n",
        "    # do upscaling here\n",
        "    #clip = core.std.DuplicateFrames(clip, frames_duplicating)\n",
        "    ###############################################\n",
        "    # COLORSPACE\n",
        "    ###############################################\n",
        "\n",
        "    # convert colorspace\n",
        "    clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "    # convert colorspace + resizing\n",
        "    # clip = vs.core.resize.Bicubic(\n",
        "    #    clip, width=1280, height=720, format=vs.RGBS, matrix_in_s=\"709\"\n",
        "    # )\n",
        "\n",
        "    ###############################################\n",
        "    # MODELS\n",
        "    ###############################################\n",
        "    # in rare cases it can happen that image range is not 0-1 and that resulting in big visual problems, clamp input\n",
        "    clip = core.akarin.Expr(clip, \"x 0 1 clamp\")\n",
        "    # clip = core.std.Limiter(clip, max=1, planes=[0,1,2])\n",
        "    #clip = scene_detect(clip, model_name=\"efficientnetv2_b0\", thresh=0.98)\n",
        "\n",
        "    ######\n",
        "    # VFI\n",
        "    ######\n",
        "\n",
        "    # VFI example for jit models\n",
        "    # clip = video_model(clip, fp16=False, model_path=\"/workspace/rvpV1_105661_G.pt\")\n",
        "\n",
        "    # Rife: model \"rife40\" up to \"rife46\" and \"sudo_rife4\"\n",
        "    # model_inference = RIFE(\n",
        "    #    scale=1, fastmode=True, ensemble=False, model_version=\"rife46\", fp16=True\n",
        "    # )\n",
        "\n",
        "    # IFRNet: model=\"small\" or \"large\"\n",
        "    # model_inference = IFRNet(model=\"small\", fp16=False)\n",
        "\n",
        "    # model_inference = GMFupSS(partial_fp16=False)\n",
        "\n",
        "    model_inference = GMFSS_union(partial_fp16=True)\n",
        "\n",
        "    # model_inference = EISAI() # 960x540\n",
        "\n",
        "    # FILM: model_choise=\"style\", \"l1\" or \"vgg\"\n",
        "    # model_inference = FILM(model_choise=\"vgg\")\n",
        "\n",
        "    # model_inference = M2M()\n",
        "\n",
        "    # model_inference = sepconv() # only 2x supported because architecture only outputs one image\n",
        "\n",
        "    # model_inference = IFUNet()\n",
        "\n",
        "    # model_inference = STMFNet()  # only 2x supported because architecture only outputs one image\n",
        "\n",
        "    clip = vfi_inference(\n",
        "        model_inference=model_inference, clip=clip, multi=2, metric_thresh=0.999\n",
        "    )\n",
        "\n",
        "    # clip = rife_trt(clip, multi = 2, scale = 1.0, device_id = 0, num_streams = 2, engine_path = \"/workspace/tensorrt/rife46.engine\")\n",
        "\n",
        "    ######\n",
        "    # UPSCALING WITH TENSORRT\n",
        "    ######\n",
        "    # vs-mlrt (you need to create the engine yourself, read the readme)\n",
        "    \"\"\"\n",
        "    clip = core.trt.Model(\n",
        "        clip,\n",
        "        engine_path=\"/workspace/tensorrt/cugan.engine\",\n",
        "        #tilesize=[854, 480],\n",
        "        overlap=[0 ,0],\n",
        "        num_streams=4,\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    # vs-mlrt (DPIR)\n",
        "    # DPIR does need an extra channel\n",
        "    # strength = 10.0\n",
        "    # noise_level = clip.std.BlankClip(format=vs.GRAYS, color=strength / 100)\n",
        "    # clip = core.trt.Model(\n",
        "    #    [clip, noise_level],\n",
        "    #    engine_path=\"dpir.engine\",\n",
        "    #    tilesize=[1280, 720],\n",
        "    #    num_streams=2,\n",
        "    # )\n",
        "\n",
        "    ######\n",
        "    # CUDA (upscaling/denoising)\n",
        "    # if possible, use mlrt from above instead due to speed\n",
        "    ######\n",
        "\n",
        "    # upscale_model_inference = PAN_inference(scale = 2, fp16 = True)\n",
        "\n",
        "    # upscale_model_inference = egvsr_inference(scale=4)\n",
        "\n",
        "    # CUGAN: kind_model=\"no_denoise\", \"conservative\" or \"denoise3x\"\n",
        "    # upscale_model_inference = cugan_inference(fp16=True,scale=2,kind_model=\"no_denoise\")\n",
        "\n",
        "    # upscale_model_inference = scunet_inference(fp16 = True)\n",
        "\n",
        "    # WARNING: FOR NOW NOT AVAILABLE DUE TO COMPATIBILITY ISSUES, use mlrt instead\n",
        "    # ESRGAN: tta is in the range between 1 and 7\n",
        "    # upscale_model_inference = ESRGAN_inference(model_path=\"/workspace/tensorrt/models/RealESRGAN_x4plus_anime_6B.pth\", fp16=False, tta=False, tta_mode=1)\n",
        "\n",
        "    # Compact: no tiling allowed due to onnx-tensorrt not allowing dynamic shapes, use mlrt instead though\n",
        "    # upscale_model_inference = compact_inference(scale=2, fp16=True, clip=clip)\n",
        "\n",
        "    # upscale_model_inference = realbasicvsr_inference(fp16=True)\n",
        "\n",
        "    # clip = upscale_inference(upscale_model_inference, clip, tile_x=512, tile_y=512, tile_pad=10, pre_pad=0)\n",
        "\n",
        "    ######\n",
        "    # external vs plugins\n",
        "    ######\n",
        "\n",
        "    # BasicVSR++\n",
        "    # 0 = REDS, 1 = Vimeo-90K (BI), 2 = Vimeo-90K (BD), 3 = NTIRE 2021 - Track 1, 4 = NTIRE 2021 - Track 2, 5 = NTIRE 2021 - Track 3\n",
        "    # clip = BasicVSRPP(\n",
        "    #    clip,\n",
        "    #    model=1,\n",
        "    #    interval=30,\n",
        "    #    tile_x=0,\n",
        "    #    tile_y=0,\n",
        "    #    tile_pad=16,\n",
        "    #    device_type=\"cuda\",\n",
        "    #    device_index=0,\n",
        "    #    fp16=False,\n",
        "    #    cpu_cache=False,\n",
        "    # )\n",
        "\n",
        "    # SwinIR\n",
        "    # clip = SwinIR(clip, task=\"lightweight_sr\", scale=2)\n",
        "\n",
        "    ###############################################\n",
        "    # ncnn (works in docker, but only on linux, because wsl on windows does not support vulkan)\n",
        "    ###############################################\n",
        "\n",
        "    # Rife ncnn (C++)\n",
        "    # Model list can be found in https://github.com/styler00dollar/VapourSynth-RIFE-ncnn-Vulkan\n",
        "    # clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "    # clip = core.rife.RIFE(\n",
        "    #    clip,\n",
        "    #    model=9,\n",
        "    #    factor_num=2,\n",
        "    #    gpu_id=0,\n",
        "    #    gpu_thread=4,\n",
        "    #    tta=False,\n",
        "    #    uhd=False,\n",
        "    #    skip=True,\n",
        "    #    sc=True,\n",
        "    # )\n",
        "\n",
        "    ######\n",
        "    # DDFI\n",
        "    # you need to use 8x interp for this\n",
        "    ######\n",
        "    # advanced example with pytorch vfi + dedup + scene change + upscaling\n",
        "\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "    # clip = core.resize.Bicubic(clip, width=1280, height=720, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "    # clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "\n",
        "    # model_inference = GMFupSS(partial_fp16=True)\n",
        "    # clip = vfi_inference(\n",
        "    #     model_inference=model_inference, clip=clip, multi=8, metric_thresh=0.999\n",
        "    # )\n",
        "\n",
        "    # clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "    # offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "    # offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "    # clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "    # clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "\n",
        "    # clip = core.trt.Model(\n",
        "    #     clip,\n",
        "    #     engine_path=\"/content/model.engine\",\n",
        "    #     num_streams=3,\n",
        "    # )\n",
        "\n",
        "    ###############################################\n",
        "    # OUTPUT\n",
        "    ###############################################\n",
        "    clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "    return clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOker8lwgE2r"
      },
      "outputs": [],
      "source": [
        "# self compiled ffmpeg / default\n",
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | ffmpeg -i pipe: /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbaKvDdAe275"
      },
      "outputs": [],
      "source": [
        "# with nix ffmpeg\n",
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | deroot ffmpeg -i pipe: -vcodec h264_nvenc /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBc_O05UnJ_5"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | x264 - --demuxer y4m -o /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY058j71oaNY"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | x265 - --y4m --crf 23 -o /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nOmKlkiDgha"
      },
      "source": [
        "# Batch inference\n",
        "Also uses `inference_config.py` for configuration, but you also need to use `main.py` to iterate over files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wQbtamr2DfvN"
      },
      "outputs": [],
      "source": [
        "#@title main.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/main.py\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "input_dir = \"/workspace/tensorrt/input/\"\n",
        "tmp_dir = \"tmp/\"\n",
        "output_dir = \"/workspace/tensorrt/output/\"\n",
        "files = glob.glob(input_dir + \"/**/*.mkv\", recursive=True)\n",
        "files.sort()\n",
        "\n",
        "for f in files:\n",
        "    # creating folders if they dont exist\n",
        "    if not os.path.exists(tmp_dir):\n",
        "        os.mkdir(tmp_dir)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "    if os.path.exists(tmp_dir):\n",
        "        shutil.rmtree(tmp_dir)\n",
        "        os.mkdir(tmp_dir)\n",
        "\n",
        "    # paths\n",
        "    txt_path = os.path.join(tmp_dir, \"tmp.txt\")\n",
        "    out_render_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_rendered.mkv\"\n",
        "    )\n",
        "    mux_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_mux.mkv\"\n",
        "    )\n",
        "\n",
        "    # only needed for dedup\n",
        "    #os.system(f\"vspipe /workspace/tensorrt/parse.py --arg source={f} -p .\")\n",
        "\n",
        "    #os.system(f\"vspipe -c y4m inference_batch.py - | ffmpeg -i pipe: {out_render_path}\")\n",
        "    #os.system(\n",
        "    #    f\"ffmpeg -y -loglevel error -i {f} -i {out_render_path}  -map 1 -map 0 -map -0:v -codec copy -max_interleave_delta 0 {mux_path}\"\n",
        "    #)\n",
        "\n",
        "    os.system(\n",
        "       f\"vspipe -c y4m inference_batch.py --arg source={f} - | ffmpeg -y -i {f} -thread_queue_size 100 -i pipe: -map 1 -map 0 -map -0:v -max_interleave_delta 0 -scodec copy -crf 10 -preset slow {mux_path}\"\n",
        "    )\n",
        "\n",
        "    # deleting temp files\n",
        "    #os.remove(txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOo2WgRSDlsa"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker\n",
        "!python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td6gkuc1ONGx"
      },
      "source": [
        "# ddfi\n",
        "\n",
        "Auto dedup-duplication inference example (More information on what exactly is meant is in [Mr-Z-2697/ddfi-rife](https://github.com/Mr-Z-2697/ddfi-rife).) Also uses `inference_config.py` for configuration, but you also need to use `deduped_vfi.py` to iterate over files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RbUC1bIRFh2d"
      },
      "outputs": [],
      "source": [
        "#@title parse.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/parse.py\n",
        "import vapoursynth as vs\n",
        "import os\n",
        "import functools\n",
        "\n",
        "core = vs.core\n",
        "core.num_threads = 4\n",
        "core.max_cache_size = 4096\n",
        "\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libfmtconv.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libmvtools.so\")\n",
        "\n",
        "# https://github.com/xyx98/my-vapoursynth-script/blob/master/xvs.py\n",
        "def props2csv(\n",
        "    clip: vs.VideoNode,\n",
        "    props: list,\n",
        "    titles: list,\n",
        "    output=\"info.csv\",\n",
        "    sep=\"\\t\",\n",
        "    charset=\"utf-8\",\n",
        "    tostring=None,\n",
        "):\n",
        "    file = open(output, \"w\", encoding=charset)\n",
        "    file.write(sep.join([\"n\"] + titles))\n",
        "    tostring = (\n",
        "        tostring\n",
        "        if callable(tostring)\n",
        "        else lambda x: x.decode(\"utf-8\")\n",
        "        if isinstance(x, bytes)\n",
        "        else str(x)\n",
        "    )\n",
        "\n",
        "    def tocsv(n, f, clip):\n",
        "        file.write(\n",
        "            \"\\n\"\n",
        "            + sep.join(\n",
        "                [str(n)]\n",
        "                + [tostring(eval(\"f.props.\" + i, globals(), {\"f\": f})) for i in props]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return clip\n",
        "        file.close()\n",
        "\n",
        "    return core.std.FrameEval(clip, functools.partial(tocsv, clip=clip), prop_src=clip)\n",
        "\n",
        "\n",
        "clip = core.ffms2.Source(globals()[\"source\"], cache=False)\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "offs1 = core.vmaf.Metric(clip, offs1, 2)\n",
        "offs1 = core.std.MakeDiff(offs1, clip)\n",
        "offs1 = core.fmtc.bitdepth(offs1, bits=16)\n",
        "offs1 = core.std.Expr(offs1, \"x 32768 - abs\")\n",
        "offs1 = core.std.PlaneStats(offs1)\n",
        "offs1 = props2csv(\n",
        "    offs1,\n",
        "    props=[\"_AbsoluteTime\", \"float_ssim\", \"PlaneStatsMax\"],\n",
        "    output=os.path.join(tmp_dir, \"infos_running.txt\"),\n",
        "    titles=[],\n",
        ")\n",
        "offs1.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xRMLV98BORGn"
      },
      "outputs": [],
      "source": [
        "#@title ddfi.py\n",
        "#@markdown edit this file to customize interpolation\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/ddfi.py\n",
        "import sys\n",
        "sys.path.append(\"/workspace/tensorrt/VSGAN-tensorrt-docker/\")\n",
        "import vapoursynth as vs\n",
        "import os\n",
        "from src.rife import RIFE\n",
        "from src.IFRNet import IFRNet\n",
        "from src.GMFupSS import GMFupSS\n",
        "from src.eisai import EISAI\n",
        "from src.film import FILM\n",
        "from src.vfi_inference import vfi_inference\n",
        "\n",
        "core = vs.core\n",
        "\n",
        "core.std.LoadPlugin(path=\"/usr/lib/x86_64-linux-gnu/libffms2.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libmvtools.so\")\n",
        "core.std.LoadPlugin(path=\"/usr/local/lib/libvstrt.so\")\n",
        "\n",
        "\n",
        "ssimt = 0.999\n",
        "pxdifft = 10240\n",
        "consecutivet = 2\n",
        "core.num_threads = 4\n",
        "core.max_cache_size = 4096\n",
        "\n",
        "tmp_dir = \"tmp/\"\n",
        "\n",
        "# frames to delete\n",
        "def processInfo():\n",
        "    with open(os.path.join(tmp_dir, \"infos_running.txt\"), \"r\") as f:\n",
        "        lines = [i.split(\"\\t\") for i in f][1:]\n",
        "    for i in range(len(lines)):\n",
        "        lines[i][0] = int(lines[i][0])\n",
        "        lines[i][1] = int(float(lines[i][1]) * 1000)\n",
        "        lines[i][2] = float(lines[i][2])\n",
        "        lines[i][3] = int(lines[i][3])\n",
        "    lines.sort()\n",
        "    startpts = lines[0][1]\n",
        "    consecutive = 0\n",
        "\n",
        "    dels = []\n",
        "    tsv2o = []\n",
        "    for i in range(len(lines)):\n",
        "        l = lines[i]\n",
        "        if l[2] >= ssimt and l[3] <= pxdifft and consecutive < consecutivet:\n",
        "            consecutive += 1\n",
        "            dels.append(l[0])\n",
        "        else:\n",
        "            consecutive = 0\n",
        "            tsv2o.append(l[1] - startpts)\n",
        "    return dels, tsv2o\n",
        "\n",
        "\n",
        "def newTSgen(tsv2o):\n",
        "    ts_new = list()\n",
        "    outfile = open(os.path.join(tmp_dir, \"tsv2nX8.txt\"), \"w\", encoding=\"utf-8\")\n",
        "    ts_o = [i for i in tsv2o][1:]\n",
        "\n",
        "    for x in range(len(ts_o) - 1):\n",
        "        ts_new.append(str(float(ts_o[x])))\n",
        "        for i in range(1, 8):\n",
        "            ts_new.append(\n",
        "                str(float(ts_o[x]) + (float(ts_o[x + 1]) - float(ts_o[x])) / 8 * i)\n",
        "            )\n",
        "    print(\"#timestamp format v2\", file=outfile)\n",
        "    for x in range(len(ts_new)):\n",
        "        print(ts_new[x], file=outfile)\n",
        "    print(ts_o[len(ts_o) - 1], file=outfile)\n",
        "    outfile.close()\n",
        "\n",
        "\n",
        "dels, tsv2o = processInfo()\n",
        "newTSgen(tsv2o)\n",
        "\n",
        "with open(os.path.join(tmp_dir, \"tmp.txt\")) as f:\n",
        "    video_path = f.readlines()[0]\n",
        "clip = core.ffms2.Source(video_path)\n",
        "clip = core.std.DeleteFrames(clip, dels)\n",
        "sup = core.mv.Super(clip, pel=1, levels=1)\n",
        "bw = core.mv.Analyse(sup, isb=True, levels=1, truemotion=False)\n",
        "clip = core.mv.SCDetection(clip, bw, thscd1=200, thscd2=85)\n",
        "\n",
        "\n",
        "# easy example with ncnn rife\n",
        "clip = core.resize.Bicubic(clip, format=vs.RGBS, matrix_in=1)\n",
        "clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "clip = core.rife.RIFE(clip, model=9, sc=True, skip=True, multiplier=8)\n",
        "\n",
        "# example for custom vfi\n",
        "\"\"\"\n",
        "clip = core.resize.Bicubic(clip, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "model_inference = RIFE(\n",
        "    scale=1, fastmode=False, ensemble=True, model_version=\"rife46\", fp16=False\n",
        ")\n",
        "# model_inference = IFRNet(model=\"small\", fp16=False)\n",
        "# model_inference = GMFupSS()\n",
        "# model_inference = EISAI() # 960x540\n",
        "# model_inference = FILM(model_choise=\"vgg\")\n",
        "clip = vfi_inference(\n",
        "    model_inference=model_inference, clip=clip, multi=8\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# advanced example with pytorch vfi + dedup + scene change + upscaling\n",
        "\"\"\"\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "clip = core.resize.Bicubic(clip, width=1280, height=720, format=vs.RGBS, matrix_in=1)\n",
        "\n",
        "clip = core.misc.SCDetect(clip=clip, threshold=0.100)\n",
        "\n",
        "model_inference = GMFupSS(partial_fp16=True)\n",
        "clip = vfi_inference(\n",
        "    model_inference=model_inference, clip=clip, multi=8\n",
        ")\n",
        "\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "offs1 = core.std.BlankClip(clip, length=1) + clip[:-1]\n",
        "offs1 = core.std.CopyFrameProps(offs1, clip)\n",
        "clip = core.vmaf.Metric(clip, offs1, 2)\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s=\"709\")\n",
        "\n",
        "clip = core.trt.Model(\n",
        "    clip,\n",
        "    engine_path=\"/content/model.engine\",\n",
        "    num_streams=3,\n",
        ")\n",
        "\"\"\"\n",
        "#######################\n",
        "\n",
        "clip = core.resize.Bicubic(\n",
        "    clip, format=vs.YUV420P10, matrix=1, dither_type=\"error_diffusion\"\n",
        ")\n",
        "clip = core.vfrtocfr.VFRToCFR(\n",
        "    clip, os.path.join(tmp_dir, \"tsv2nX8.txt\"), 192000, 1001, True\n",
        ")  # 24fps * 8\n",
        "sup = core.mv.Super(clip)\n",
        "fw = core.mv.Analyse(sup)\n",
        "bw = core.mv.Analyse(sup, isb=True)\n",
        "clip = core.mv.FlowFPS(clip, sup, bw, fw, 60, 1)\n",
        "clip.set_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xysVSWfzCzhk"
      },
      "outputs": [],
      "source": [
        "#@title deduped_vfi.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/deduped_vfi.py\n",
        "import glob\n",
        "import os\n",
        "\n",
        "input_dir = \"/workspace/tensorrt/VSGAN-tensorrt-docker/input/\"\n",
        "tmp_dir = \"tmp/\"\n",
        "output_dir = \"/workspace/tensorrt/VSGAN-tensorrt-docker/output/\"\n",
        "files = glob.glob(input_dir + \"/**/*.mkv\", recursive=True)\n",
        "files.sort()\n",
        "\n",
        "for f in files:\n",
        "    # creating folders if they dont exist\n",
        "    if os.path.exists(tmp_dir) == False:\n",
        "        os.mkdir(tmp_dir)\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # paths\n",
        "    txt_path = os.path.join(tmp_dir, \"tmp.txt\")\n",
        "    out_render_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_rendered.mkv\"\n",
        "    )\n",
        "    mux_path = os.path.join(\n",
        "        output_dir, os.path.splitext(os.path.basename(f))[0] + \"_mux.mkv\"\n",
        "    )\n",
        "\n",
        "    # writing filepath into temp txt\n",
        "    # workaround to pass filename parameter\n",
        "    f_txt = open(txt_path, \"w\")\n",
        "    f_txt.write(str(f))\n",
        "    f_txt.close()\n",
        "\n",
        "    os.system(\"vspipe parse.py -p .\")\n",
        "    os.system(\n",
        "        f\"vspipe -c y4m ddfi.py - | ffmpeg -i pipe: -vcodec libsvtav1 -crf 20 {out_render_path}\"\n",
        "    )\n",
        "\n",
        "    os.system(\n",
        "        f\"ffmpeg -y -loglevel error -i {f} -i {out_render_path}  -map 1 -map 0 -map -0:v -codec copy -max_interleave_delta 0 {mux_path}\"\n",
        "    )\n",
        "\n",
        "    # deleting temp files\n",
        "    os.remove(txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83z9ZpctOWjE"
      },
      "outputs": [],
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!python deduped_vfi.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "_a3Fp70p-LND",
        "2nOmKlkiDgha"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
